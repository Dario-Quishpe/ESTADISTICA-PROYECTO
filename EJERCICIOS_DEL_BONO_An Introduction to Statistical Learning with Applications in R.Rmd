---
title: "EJERCICIOS DEL BONO (An Introduction to Statistical Learning with Applications in R)"
author: "Dario Quishpe"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Capitulo 5 - Ejercicio 2

Ahora derivaremos la probabilidad de que una observación dada sea parte de una muestra bootstrap. Supongamos que obtenemos una muestra bootstrap a partir de un conjunto de n observaciones.

**a.** ¿Cuál es la probabilidad de que la primera observación bootstrap **no** sea la $j$-ésima observación de la muestra original? Justifica tu respuesta.

Esto es $1$ menos la probabilidad de que sea la $j$-ésima, es decir, $1 - \frac{1}{n}$.

**b**. ¿Cuál es la probabilidad de que la segunda observación bootstrap **no** sea la $j$-ésima observación de la muestra original?

Dado que cada observación bootstrap es una muestra aleatoria, esta probabilidad es la misma, $1 - \frac{1}{n}$.

**c.** Argumenta que la probabilidad de que la $j$-ésima observación **no** esté en la muestra bootstrap es $(1 - \frac{1}{n})^n$.

Para que la $j$-ésima observación no esté en la muestra, no debería ser elegida para cada una de las $n$ posiciones, es decir, no seleccionada para $1, 2, ..., n$. Por lo tanto, la probabilidad es $(1 - \frac{1}{n})^n$.

**d.** Cuando $n = 5$, ¿cuál es la probabilidad de que la $j$-ésima observación esté en la muestra bootstrap?
```{r}
n <- 5
1 - (1 - 1 / n)^n
```

**e**. Cuando $n = 100$, ¿cuál es la probabilidad de que la $j$-ésima observación esté en la muestra bootstrap?
```{r}
n <- 100
1 - (1 - 1 / n)^n
```

**f.** Cuando $n = 10,000$, ¿cuál es la probabilidad de que la $j$-ésima observación esté en la muestra bootstrap?
```{r}
n <- 100000
1 - (1 - 1 / n)^n
```
**g.** Crea un gráfico que muestre, para cada valor entero de $n$ de 1 a 100,000, la probabilidad de que la $j$-ésima observación esté en la muestra bootstrap. Comenta sobre lo que observas.
```{r}
x <- sapply(1:100000, function(n) 1 - (1 - 1 / n)^n)
plot(x, log = "x", type = "o",main="Probabilidades")
abline(h=0.63,col="red")
```
La probabilidad se aproxima rápidamente a 0.63 con el aumento de $n$.

Nota que
\[
e^x = \lim_{{x \to \infty}} \left(1 + \frac{x}{n}\right)^n,
\]
entonces con $x = -1$, podemos ver que nuestro límite es $1 - e^{-1} = 1 - \frac{1}{e}$.

**h.** Investigaremos numéricamente la probabilidad de que una muestra bootstrap de tamaño $n = 100$ contenga la $j$-ésima observación. Aquí $j = 4$. Creamos repetidamente muestras bootstrap y cada vez registramos si la cuarta observación está contenida en la muestra bootstrap.



```{r}
store <- rep(NA, 10000)
for (i in 1:10000) {
  store[i] <- sum(sample(1:100, replace = TRUE) == 4) > 0
}
mean(store)
```


Comenta sobre los resultados obtenidos.
```{r}
store <- replicate(10000, sum(sample(1:100, replace = TRUE) == 4) > 0)
mean(store)

```

La probabilidad de incluir el $4$ al remuestrear números del $1$ al $100$ se acerca a $1 - \left(1 - \frac{1}{100}\right)^{100}$.



# Capitulo 5 - Ejercicio 2

En el Capítulo 4, utilizamos regresión logística para predecir la probabilidad de `default` utilizando `income` y `balance` en el conjunto de datos `Default`. Ahora estimaremos el error de prueba de este modelo de regresión logística utilizando el enfoque de conjunto de validación. No olvides establecer una semilla aleatoria antes de comenzar tu análisis.

**a.** Ajusta un modelo de regresión logística que utilice `income` y `balance` para predecir `default`.
```{r}
#install.packages("ISLR2")
library(ISLR2)
set.seed(42)
modelo <- glm(default ~ income + balance, data = Default, family = "binomial")
summary(modelo)
```

**b.** Utilizando el enfoque de conjunto de validación, estima el error de prueba de este modelo. Para hacer esto, debes realizar los siguientes pasos:
    i. Divide el conjunto de muestras en un conjunto de entrenamiento y un conjunto de validación.
    ii. Ajusta un modelo de regresión logística múltiple utilizando solo las observaciones de entrenamiento.
    iii. Obtiene una predicción del estado de `default` para cada individuo en el conjunto de validación calculando la probabilidad posterior de `default` para ese individuo y clasificando al individuo en la categoría `default` si la probabilidad posterior es mayor que 0.5.
    iv. Calcula el error del conjunto de validación, que es la fracción de observaciones en el conjunto de validación que están mal clasificadas.

```{r}
train <- sample(nrow(Default), nrow(Default) / 2)
modelo <- glm(default ~ income + balance, data = Default, family = "binomial", subset = train)
prediccion <- ifelse(predict(modelo, newdata = Default[-train, ], type = "response") > 0.5, "SI", "No")
table(prediccion, Default$default[-train])
mean(prediccion != Default$default[-train])
```
**c.** Repite el proceso en (b) tres veces, utilizando tres divisiones diferentes de las observaciones en un conjunto de entrenamiento y un conjunto de validación. Comenta sobre los resultados obtenidos.

```{r}
replicate(3, {
  train <- sample(nrow(Default), nrow(Default) / 2)
  modelo <- glm(default ~ income + balance, data = Default, family = "binomial", subset = train)
  prediccion <- ifelse(predict(modelo, newdata = Default[-train, ], type = "response") > 0.5, "SI", "No")
  mean(prediccion != Default$default[-train])
})
```

Los resultados obtenidos son variables y dependen de las muestras asignadas a entrenamiento vs prueba(similar a Training test).

**d.** Ahora considera un modelo de regresión logística que predice la probabilidad de `default` utilizando `income`, `balance`, y una variable ficticia para `student`. Estima el error de prueba para este modelo utilizando el enfoque de conjunto de validación. Comenta si incluir una variable ficticia para `student` conduce o no a una reducción en la tasa de error de prueba.
```{r}
replicate(3, {
  train <- sample(nrow(Default), nrow(Default) / 2)
  modelo <- glm(default ~ income + balance + student, data = Default, family = "binomial", subset = train)
  predichos <- ifelse(predict(modelo, newdata = Default[-train, ], type = "response") > 0.5, "SI", "No")
  mean(predichos != Default$default[-train])
})
```

Incluir `student` no parece mejorar sustancialmente el error de prueba.

# Capitulo 5 - Ejercicio 2

Continuamos considerando el uso de un modelo de regresión logística para predecir la probabilidad de `default` utilizando `income` y `balance` en el conjunto de datos `Default`. En particular, ahora calcularemos estimaciones para los errores estándar de los coeficientes de regresión logística para `income` y `balance` de dos maneras diferentes: (1) usando el bootstrap y (2) usando la fórmula estándar para calcular los errores estándar en la función `glm()`. No olvides establecer una semilla aleatoria antes de comenzar tu análisis.

**a.** Utilizando las funciones `summary()` y `glm()`, determina los errores estándar estimados para los coeficientes asociados con `income` y `balance` en un modelo de regresión logística múltiple que utiliza ambos predictores.
```{r}
set.seed(1)
modelo <- glm(default ~ income + balance, data = Default, family = "binomial")
summary(modelo)
```
Los errores estándar obtenidos mediante el bootstrap son $\beta_1$ = 2.081e-05 y $\beta_2$ = 5.647e-03.

**b.** Escribe una función, `boot.fn()`, que tome como entrada el conjunto de datos `Default` así como un índice de las observaciones, y que devuelva las estimaciones de coeficientes para `income` y `balance` en el modelo de regresión logística múltiple.
```{r}
boot.fn <- function(x, i) {
  modelo <- glm(default ~ income + balance, data = x[i, ], family = "binomial")
  coef(modelo)[-1]
}
```
**c.** Usa la función `boot()` junto con tu función `boot.fn()` para estimar los errores estándar de los coeficientes de regresión logística para `income` y `balance`.

```{r, cache = TRUE}
library(boot)
set.seed(1)
#boot(Default,boot.fn,R=10)
boot::boot(Default,boot.fn,R=10)
```

**d.** Comenta sobre los errores estándar estimados obtenidos utilizando la función `glm()` y tu función de bootstrap.


Los errores estándar obtenidos mediante bootstrapping son similares a los estimados
por `glm`.

