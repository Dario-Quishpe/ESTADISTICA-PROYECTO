---
title: "PROYECTO FINAL DE ESTADISTICA MATEMATICA"
author: "Armando Lara, Dario Quishpe , Jorge Arguello"
date: "`r Sys.Date()`"
output:
  pdf_document: 
    latex_engine: xelatex
    fig_caption: true
    fig_height: 3.5
    toc: true
    number_sections: true
  html_document: default
header-includes:
   - \usepackage{graphicx}
   
---

# Introducción

Para una coperativa de ahorro y crédito es fundamental el análisis de La solvencia financiera de sus socios pues es un  factor crítico al evaluar las distintas solicitudes de créditos permitiendo tomar  decisiones sobre las mismas.Estás decisiones tienen impacto directo en los diferentes indicadores que son de gran relevancia en la institución para su monitoreo y supervisión. Dentro de estos se encuentran indicadores de mora por productos crediticios, porcentaje de colocación,riesgo crediticio ,etc.Está medida de solvencia nos proporciona una visión  de la capacidad  que tienen los socios para cumplir con sus obligaciones financieras, ya que en caso de un indicador de solvencia saludable  sugiere una menor probabilidad de incumplimiento en el pago de deudas,  así como también  permite a la cooperativa tomar decisiones de crédito informadas y personalizadas,dando oportunidad de  adaptar los términos del crédito u ofrecer productos convenientes según la solvencia individual.

La coperativa de ahorro y credito denominada "X"  ,en vista de la importancia de la información otorgada por este indicador  a optado por hacer el acompañamiento de tecnicas estadísticas  a las decisiones de los analistas sobre los créditos. El presente proyecto intenta poner como un punto de partida el estudio de este indicador en un conjunto de socios.  
# Metodología

## 2.1 Recolección de los datos

Se obtuvo una base de datos de solicitudes de crédito de una Cooperativa importante del país, la cual contiene información sobre variables relevantes, incluyendo el patrimonio neto y los activos de los solicitantes. Por cuestiones de confidencialidad de los clientes de dicha cooperativa, se omitió las variables con respecto a información personal de los solicitantes, tomando únicamente para nuestro interés en este trabajo sólo las variables que necesitamos.

## 2.2 Construcción del Indicador de solvencia

Dentro de una cooperativa, es importante la representación de la capacidad financiera mediante un indicador, el patrimonio neto representa la cantidad de flujo con la que está a disposición la cooperativa para hacer frente a situaciones futuras. Por lo tanto, dividir el patrimonio neto por los activos totales proporciona una medida de la capacidad de una entidad para cubrir sus obligaciones con sus activos.

Por lo tanto, se construye el indicador de solvencia cómo:

\begin{equation*}
I=Patrimonio neto/Activos
\end{equation*}

## 2.3 Análisis Exploratorio

Se procederá a realizar diversos gráficos y pruebas estadísticas para identificar la distribución de cada variable, incluyendo el indicador de solvencia. El objetivo principal es obtener una distribución que se ajuste a una mixtura de distribuciones normales para nuestro indicador.

## Estimación de parámetros mediante el Algoritmo EM
Mediante el algoritmo EM Expectation-Maximization, se procederá a estimar los parámetros del indicador de solvencia. Este algoritmo permitirá identificar los parámetros óptimos de la distribución (en un principio desconocida) del indicador de solvencia. Este algoritmo nos será de gran utilidad, pues una vez estimados los parámetros se los usará para hacer inferencia e identificar su distribución.


## Prueba de distribución de mixturas normales
Una vez que se obtenga los parámetros como la media, la varianza y los pesosse aplicará un test estadístico apropiado para comprobar si la distribución del indicador es una Mixtura de distribuciones normales, dicho test fue realizado por Priscila Guayasamín para la clasificación de cooperativas por segmentos. En el caso en que el test rechace la hipótesis de mixturas de distribuciones normales, se procederá a la transformación de nuestros datos como una logarítmica, Box-Cox, etc.

## Simulación de datos mediante los parámetros obtenidos
Si mediante el test desarrollado por Priscila se obtiene que hay evidencia estadística para aceptar que la distribución del indicador es una mixtura de normales, se procederá a realizar la simulación de nuevos datos para el indicador de solvencia, en esta simulación se incluirá los parámetros obtenidos por el algoritmo EM y con una distribución de mixtura de normales. Esto servirá para realizar intervalos de confianza del indicador así como constrastes de hipótesis.

```{r setup, include=FALSE}
library(readxl)
library(tidyverse)
library(tidyverse)
library(energy)
library(mixtools)
library(ks)
library(plotly)
library(gridExtra)
# Cargar el paquete MVN
library(MVN)
library(ICS)
library(car)
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

#base<-read_xlsx("Solicitudes_Crédito.xlsx")
#dim(base)
load("BASE_SOLICITUD_DE_CREDITO.RData")
#BASE1
```

```{r}
test_mixturasnormales<-function(data,mus,sigmapob,lambdapob){
if (!is.data.frame(data) && !is.matrix(data))
stop('data supplied must be either of class \"data frame\" or \"matrix\"')
if (dim(data)[2] < 2 || is.null(dim(data)))
{stop("data dimesion has to be more than 1")}
if (dim(data)[1] < 3) {stop("not enough data for assessing mvn")}
data.name <- deparse(substitute(data))
xp <- as.matrix(data)
p <- dim(xp)[2]
n <- dim(xp)[1]
## getting MLEs...
s.mean <- colMeans(xp)
s.cov <- (n-1)/n*cov(xp)
s.cov.inv <- solve(s.cov) # inverse matrix of S (matrix of sample covariances)
D <- rep(NA,n) # vector of (Xi-mu)'S^-1(Xi-mu)...
for (j in 1:n)
D[j] <- t(xp[j,]-s.mean) %*%(s.cov.inv %*%(xp[j,]-s.mean))
D.or <- sort(D) ## get ordered statistics
Gp <- pchisq(D.or,df=p)
## getting the value of A-D test...
ind <- c(1:n)
an <- (2*ind-1)*(log(Gp[ind])+log(1 - Gp[n+1-ind]))
AD <- -n - sum(an) / n
## getting the p-value...
N <- 1e4
U <- rep(0,N) ## initializing values of the AD test
for (i in 1:N) { ## loop through N reps
dat<-rmvnorm.mixt(1000, mus=mus, Sigmas=sigmapob, props=lambdapob)
mean1 <- colMeans(dat)
cov1 <- (n-1)/n*cov(dat)
cov.inv <- solve(cov1) # inverse matrix of S (matrix of sample covariances)
D <- rep(NA,n) # vector of (Xi-mu)'S^-1(Xi-mu)...
for (j in 1:n)
D[j] <- t(data[j,]-mean1)%*%(cov.inv %*%(data[j,]-mean1))
Gp <- pchisq(sort(D),df=p)
## getting the value of A-D test...
an <- (2*ind-1)*(log(Gp[ind])+log(1 - Gp[n+1-ind]))
U[i] <- -n - sum(an) / n
}
p.value <- (sum(U >= AD)+1)/(N+1)
return(p.value)
}
```

```{r}
G1<-ggplot(data.frame(x = BASE1$TOTAL_PATRIMONIO_NETO), aes(x)) +
  geom_histogram(aes(y = ..density..), bins = 20, color = "white", fill = "lightblue", alpha = 0.7) +geom_density(color = "darkred", size = 1) + labs(title = "Total Patrimonio Neto")

G2<-ggplot(data.frame(x = BASE1$TOTAL_ACTIVO), aes(x)) +
  geom_histogram(aes(y = ..density..), bins = 20, color = "white", fill = "lightblue", alpha = 0.7) +geom_density(color = "darkred", size = 1) + labs(title = "Total activo")

G3<-ggplot(data.frame(x = BASE1$Alog), aes(x)) +
  geom_histogram(aes(y = ..density..), bins = 20, color = "white", fill = "lightblue", alpha = 0.7) +geom_density(color = "darkred", size = 1) + labs(title = "Log(Patrimonio Neto)")

G4<-ggplot(data.frame(x = BASE1$Blog), aes(x)) +
  geom_histogram(aes(y = ..density..), bins = 20, color = "white", fill = "lightblue", alpha = 0.7) +geom_density(color = "darkred", size = 1) + labs(title = "Log(Total activo)")

grid.arrange(G1,G2,G3,G4)
G5<-ggplot(data.frame(x = BASE1$TOTAL_PATRIMONIO_NETO), aes(x)) +
  geom_boxplot()  + labs(title = "Total Patrimonio Neto")
G6<-ggplot(data.frame(x = BASE1$TOTAL_ACTIVO), aes(x)) +
  geom_boxplot()  + labs(title = "Total Activo")
G7<-ggplot(data.frame(x = BASE1$Alog), aes(x)) +
  geom_boxplot()  + labs(title = "Log(Patrimonio neto)")
G8<-ggplot(data.frame(x = BASE1$Blog), aes(x)) +
  geom_boxplot()  + labs(title = "Log(Total activo)")
grid.arrange(G5,G6,G7,G8)

```

```{r}
BASE1
dim(BASE1)
a<-(BASE1$Alog)
b<-(BASE1$Blog)
dim(BASE1)
A<-matrix(c(a,b),nrow=660 ,ncol=2)#Con logaritmo funciono
set.seed(123)
data <- A
rownames(data) <- paste0("Obs", 1:nrow(data))
colnames(data) <- c("Var1", "Var2")
em<-mvnormalmixEM(A)
mu<-rbind(em$mu[[1]],em$mu[[2]])
sigma<-rbind(em$sigma[[1]],em$sigma[[2]])
p<-test_mixturasnormales(A,mu,sigma,as.vector(em$lambda))
```





```{r}
#MONTECARLO
media<-vector(length = 5000)
var<-vector(length = 5000)
sd<-vector(length = 5000)
for(i in 1:5000){
dat<-rmvnorm.mixt(5000,mus = mu,Sigmas = sigma,props = as.vector(em$lambda))
indicador_sim<-dat[,1]-dat[,2]
media[i]<-mean(indicador_sim)
var[i]<-var(indicador_sim)
sd[i]<-sd(indicador_sim)
}
liminfMonte<-quantile(media,0.05)
limisupMonte<-quantile(media,1-0.05)
MediaMonte<-mean(media)
Var_Montemean<-mean(var)
SdMonte<-mean(sd)
liminfMonte
limisupMonte
MediaMonte
Var_Montemean
SdMonte
#Valores retransformados 
LIINF<-exp(liminfMonte)
LIMSUP<-exp(limisupMonte)
MEDIA<-exp(MediaMonte)
VAR<-exp(Var_Montemean)
SD<-exp(SdMonte)
LIINF
LIMSUP
MEDIA
VAR
SD
```
```{r}
plot(density(indicador_sim),col="red")
lines(density(BASE1$indlog),col="blue")
legend("topright", legend = c("MUESTRA", "Montecarlo"), col = c("blue", "red"), lty = c(1, 1))
```


\begin{table}[!h]
    \centering
    \caption{\textbf{Estimaciones por Montecarlo y Bootstrap (Datos Transformados)}}
    \begin{tabular}{|l|l|l|l||l}
    \hline
        Metodo$\backslash$ Medida &Media & Varianza & Sd & LINF & LimSUP \\ \hline
        Montecarlo & -0.3285 & 0.1554 & 0.3942&  -0.33790 & -0.31939\\ \hline
        Boots & 0.225 & 0.235 & 0.221& 5 & 4 \\ \hline
      
    \end{tabular}
\end{table}

\begin{table}[!h]
    \centering
    \caption{\textbf{Estimaciones por Montecarlo y Bootstrap (Datos Originales)}}
    \begin{tabular}{|l|l|l|l||l}
    \hline
        Metodo$\backslash$ Medida & Media & Varianza & Sd & LINF & LimSUP \\ \hline
        Montecarlo & 0.719& 1.1681 & 1.483255 &0.71326 & 0.72658 \\ \hline
        Boots & 0.225 & 0.235 & 0.221 & 02 & 1 \\ \hline
            \end{tabular}
\end{table}

\begin{table}[!h]
    \centering
    \caption{\textbf{Estimaciones por Montecarlo y Bootstrap (Datos Originales)}}
    \begin{tabular}{|l|l|l}
    \hline
        Metodo$\backslash$Medida & SESGO MEDIA & SESGO Varianza & SESGO Sd  \\ \hline
        Montecarlo & -0.0464 & 1.1166 &0.1671\\ \hline
        Boots & 0.225 & 0.235 & 4 \\ \hline
            \end{tabular}
\end{table}



```{r}
#SESGO
SesgoMedia<-MEDIA-mean(BASE1$IndSolvencia)
SesgoVar<-VAR-var(BASE1$IndSolvencia)
SesgoSd<-SdMonte-sd(BASE1$IndSolvencia)

SesgoMedia

SesgoVar

SesgoSd
```


```{r}
#CONTRASTE DE HIPOTESIS datos transformados(log)
#HO:mu=-0.34
numsimu<-1000
pvalue<-numeric(numsimu)
for (i in 1:numsimu){
dat<-rmvnorm.mixt(5000,mus = mu,Sigmas = sigma,props = as.vector(em$lambda))
indicador_sim<-dat[,1]-dat[,2]
ind<-(indicador_sim)
estadistico<-(mean(ind)+0.34)/(sd(ind)/sqrt(5000))
p<-1-pt(abs(estadistico),5000-1)+pt(-abs(estadistico),5000-1)
pvalue[i]<-p
}

cat("\nProporción de rechazos al 1%=",mean(pvalue<0.01),"\n")
cat("\nProporción de rechazos al 5%=",mean(pvalue<0.05),"\n")
cat("\nProporción de rechazos al 10%=",mean(pvalue<0.1),"\n")
```


```{r}


#mvnorm.kur.test(A,n.simu = 1000)
#qqPlot(data, main = "Q-Q Plot Multivariado")
# Realizar la prueba de normalidad multivariante
#mvn(data, mvnTest = "hz",covariance = TRUE, showOutliers = TRUE,multivariatePlot = TRUE,tol=0.005)
N<-mvn(data, mvnTest = "mardia",multivariatePlot = "persp",tol =0.005)
M<-mvn(data, mvnTest = "mardia",multivariatePlot = "qq",tol =0.005 )
O<-mvn(data, mvnTest = "mardia",multivariatePlot = "contour",tol =0.005 )
# Mostrar los resultados
#print(result)

```





```{r}
data<-dat
#mvnorm.kur.test(dat,n.simu = 1000)
#qqPlot(data, main = "Q-Q Plot Multivariado")
# Realizar la prueba de normalidad multivariante
#mvn(data, mvnTest = "hz",covariance = TRUE, showOutliers = TRUE,multivariatePlot = TRUE,tol=0.005)
R<-mvn(data, mvnTest = "mardia", showOutliers = TRUE,multivariatePlot = "persp",tol =0.005,transform = "log" )
S<-mvn(data, mvnTest = "mardia", showOutliers = TRUE,multivariatePlot = "qq",tol =0.005 )
Q<-mvn(data, mvnTest = "mardia", showOutliers = TRUE,multivariatePlot = "contour",tol =0.005 )
```










